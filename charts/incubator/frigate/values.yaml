image:
  repository: tccr.io/truecharts/frigate
  pullPolicy: IfNotPresent
  tag: v0.12.0@sha256:6fac983662fc6095ffdc8dd494f0c918192ddab80602f01d50a3569dab868148

securityContext:
  container:
    readOnlyRootFilesystem: false
    runAsNonRoot: false
    runAsUser: 0
    runAsGroup: 0
# -- The "render_config" key is only used internally to "render" or not the configuration
# - Some parts of the config bellow are slightly modified so they can be added on SCALE UI. Mainly lists.
# - Do not blindly copy paste configuration from upstream. As this won't work on all cases
# - Where you see "null" set as default is ignored by the configmap. (Not all keys are supported).
# - Those "nulls" should be replaced with integers (if you want to set a value)
frigate:
  mqtt:
    # -- Enable it to add the configuration in the config file
    render_config: true
    # -- Enables MQTT
    enabled: false
    host: mqtt.server.com
    port: 1883
    # -- NOTE: Must be unique if you are running multiple instances
    topic_prefix: ""
    # -- NOTE: Must be unique if you are running multiple instances
    client_id: ""
    user: ""
    password: ""
    stats_interval: 60

  detectors:
    # -- Enable it to add the configuration in the config file
    render_config: false
    config: []
    # -- Required: Name of the detector
    # - name: coral
    #   # -- Valid values are 'edgetpu' (requires device property below) and 'cpu'.
    #   type: edgetpu
    #   # -- Device name as defined here: https://coral.ai/docs/edgetpu/multiple-edgetpu/#using-the-tensorflow-lite-python-api
    #   device: usb
    #   # -- This value is only used for CPU types
    #   num_threads: 3

  model:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Required: Object detection model input width
    width: 320
    # -- Required: Object detection model input height
    height: 320
    # -- Optional: Path to the model
    path: ""
    # -- Optional: Path to the labelmap
    labelmap_path: ""
    # -- Optional: Label name modifications.
    labelmap: []
    # - model: "2"
    #   name: vehicle
    # - model: 3
    #   name: vehicle

  logger:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Optional: Default log verbosity (default: shown below)
    default: info
    # -- Optional: Component specific logger overrides
    logs: []
    # - component: frigate.event
    #   verbosity: debug

  birdseye:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Enables birdseye
    enabled: true
    # -- Optional: Width of the output resolution
    width: null
    # -- Optional: Height of the output resolution
    height: null
    # -- Optional: Encoding quality of the mpeg1 feed
    # - 1 is the highest quality, and 31 is the lowest. Lower quality feeds utilize less CPU resources.
    quality: null
    # -- Optional: Mode of the view. Available options are: objects, motion, and continuous
    # - objects - cameras are included if they have had a tracked object within the last 30 seconds
    # - motion - cameras are included if motion was detected in the last 30 seconds
    # - continuous - all cameras are included always
    mode: ""

  ffmpeg:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Optional: global ffmpeg args
    global_args: ""
    # -- Optional: global input args
    input_args: ""
    # -- Optional: global hwaccel args
    # - NOTE: See hardware acceleration docs for your specific device
    hwaccel_args: ""
    # -- Optional: global output args
    output_args:
      # -- Optional: output args for detect streams
      detect: ""
      # -- Optional: output args for record streams
      record: ""
      # -- Optional: output args for rtmp streams
      rtmp: ""

  detect:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Enables detection for the camera.
    # - This value can be set via MQTT and will be updated in startup based on retained value
    enabled: true
    # -- Optional: width of the frame for the input with the detect role
    width: null
    # -- Optional: height of the frame for the input with the detect role
    height: null
    # -- Optional: desired fps for your camera for the input with the detect role
    # - NOTE: Recommended value of 5. Ideally, try and reduce your FPS on the camera.
    fps: null
    # -- Optional: Number of frames without a detection before frigate considers an object to be gone. (default: 5x the frame rate)
    max_disappeared: null
    # -- Optional: Configuration for stationary object tracking
    stationary:
      # -- Optional: Frequency for confirming stationary objects
      # - When set to 0, object detection will not confirm stationary objects until movement is detected.
      # - If set to 10, object detection will run to confirm the object still exists on every 10th frame.
      interval: null
      # -- Optional: Number of frames without a position change for an object to be considered stationary (default: 10x the frame rate or 10s)
      threshold: null
      # -- Optional: Define a maximum number of frames for tracking a stationary object (default: not set, track forever)
      # - This can help with false positives for objects that should only be stationary for a limited amount of time.
      # - It can also be used to disable stationary object tracking. For example, you may want to set a value for person, but leave
      # - car at the default.
      # - WARNING: Setting these values overrides default behavior and disables stationary object tracking.
      # - There are very few situations where you would want it disabled. It is NOT recommended to
      # - copy these values from the example config into your config unless you know they are needed.
      # max_frames:
      #   # -- Optional: Default for all object types (default: not set, track forever)
      #   default:
      #   # -- Optional: Object specific values
      #   objects:
      #     - object: person
      #       frames: 1000

  objects:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Optional: list of objects to track from labelmap.txt
    track: []
    # - person
    # - car
    # -- Optional: mask to prevent all object types from being detected in certain areas (default: no mask)
    # - Checks based on the bottom center of the bounding box of the object.
    # - NOTE: This mask is COMBINED with the object type specific mask below
    mask: ""
    # - Optional: filters to reduce false positives for specific object types
    filters: []
    # - object: person
    #   # -- Optional: Minimum width*height of the bounding box for the detected object
    #   min_area: 5000
    #   # -- Optional: Maximum width*height of the bounding box for the detected object
    #   max_area: 100000
    #   # -- Optional: Minimum width/height of the bounding box for the detected object
    #   min_ratio: "0.5"
    #   # -- Optional: Maximum width/height of the bounding box for the detected object
    #   max_ratio: "2.0"
    #   # -- Optional: Minimum score for the object to initiate tracking
    #   min_score: "0.5"
    #   # -- Optional: Minimum decimal percentage for tracked object's computed score to be considered a true positive
    #   threshold: "0.7"
    #   # -- Optional: Mask to prevent this object type from being detected in certain areas
    #   # - Checks based on the bottom center of the bounding box of the object
    #   mask: 0,0,1000,0,1000,200,0,200

  motion:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Optional: The threshold passed to cv2.threshold to determine if a pixel is different enough to be counted as motion.
    # - Increasing this value will make motion detection less sensitive and decreasing it will make motion detection more sensitive.
    # - The value should be between 1 and 255.
    threshold: null
    # -- Optional: Minimum size in pixels in the resized motion image that counts as motion
    # - Increasing this value will prevent smaller areas of motion from being detected. Decreasing will
    # - make motion detection more sensitive to smaller moving objects.
    # - As a rule of thumb:
    # - 15 - high sensitivity
    # - 30 - medium sensitivity
    # - 50 - low sensitivity
    contour_area: null
    # -- Optional: Alpha value passed to cv2.accumulateWeighted when averaging the motion delta across multiple frames
    # - Higher values mean the current frame impacts the delta a lot, and a single raindrop may register as motion.
    # - Too low and a fast moving person wont be detected as motion.
    delta_alpha: ""
    # -- Optional: Alpha value passed to cv2.accumulateWeighted when averaging frames to determine the background
    # - Higher values mean the current frame impacts the average a lot, and a new object will be averaged into the background faster.
    # - Low values will cause things like moving shadows to be detected as motion for longer.
    # - https://www.geeksforgeeks.org/background-subtraction-in-an-image-using-concept-of-running-average/
    frame_alpha: ""
    # -- Optional: Height of the resized motion frame  (default: 50)
    # - This operates as an efficient blur alternative. Higher values will result in more granular motion detection at the expense
    # - of higher CPU usage. Lower values result in less CPU, but small changes may not register as motion.
    frame_height: null
    # -- Optional: motion mask
    # - NOTE: see docs for more detailed info on creating masks
    mask: ""
    # -- Optional: improve contrast
    # - Enables dynamic contrast improvement. This should help improve night detections at the cost of making motion detection more sensitive
    # - for daytime.
    improve_contrast: false
    # -- Optional: Delay when updating camera motion through MQTT from ON -> OFF
    mqtt_off_delay: null

  record:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Optional: Enable recording
    # - WARNING: If recording is disabled in the config, turning it on via
    # - the UI or MQTT later will have no effect.
    # - WARNING: Frigate does not currently support limiting recordings based
    # - on available disk space automatically. If using recordings,
    # - you must specify retention settings for a number of days that
    # - will fit within the available disk space of your drive or Frigate will crash.
    enabled: false
    # -- Optional: Number of minutes to wait between cleanup runs
    # - This can be used to reduce the frequency of deleting recording segments from disk if you want to minimize i/o
    expire_interval:
    # -- Optional: Retention settings for recording
    retain:
      # -- Render retain config
      render_config: false
      # -- Optional: Number of days to retain recordings regardless of events
      # - NOTE: This should be set to 0 and retention should be defined in events section below
      # - if you only want to retain recordings of events.
      days:
      # -- Optional: Mode for retention. Available options are: all, motion, and active_objects
      # - all - save all recording segments regardless of activity
      # - motion - save all recordings segments with any detected motion
      # - active_objects - save all recording segments with active/moving objects
      # - NOTE: this mode only applies when the days setting above is greater than 0
      mode: ""
    # -- Optional: Event recording settings
    events:
      # -- Enable it to add the configuration in the config file
      render_config: false
      # -- Optional: Number of seconds before the event to include
      pre_capture: null
      # -- Optional: Number of seconds after the event to include
      post_capture: null
      # -- Optional: Objects to save recordings for. Defaults to all
      objects: []
      # - person
      # -- Optional: Restrict recordings to objects that entered any of the listed zones
      required_zones: []
      # -- Optional: Retention settings for recordings of events
      retain:
        # -- Render retain config
        render_config: false
        # -- Required: Default retention days
        default: 10
        # -- Optional: Mode for retention.
        # - all - save all recording segments for events regardless of activity
        # - motion - save all recordings segments for events with any detected motion
        # - active_objects - save all recording segments for event with active/moving objects
        mode: ""
        # -- Optional: Per object retention days
        objects: []
        # - object: person
        #   days: 15

  snapshots:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Optional: Enable writing jpg snapshot to /media/frigate/clips
    # - This value can be set via MQTT and will be updated in startup based on retained value
    enabled: false
    # -- Optional: Save a clean PNG copy of the snapshot image
    clean_copy: true
    # -- Optional: print a timestamp on the snapshots
    timestamp: false
    # -- Optional: draw bounding box on the snapshots
    bounding_box: false
    # -- Optional: crop the snapshot
    crop: false
    # -- Optional: height to resize the snapshot to (default: original size)
    height:
    # -- Optional: Restrict snapshots to objects that entered any of the listed zones (default: no required zones)
    required_zones: []
    # -- Optional: Camera override for retention settings (default: global values)
    retain:
      # -- Render retain config
      render_config: false
      # -- Required: Default retention days (default: shown below)
      default: 10
      # -- Optional: Per object retention days
      objects: []
      # - object: person
      #   days: 15

  rtmp:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # - Optional: Enable the RTMP stream
    enabled: true

  live:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Optional: Set the height of the live stream. (default: 720)
    # - This must be less than or equal to the height of the detect stream. Lower resolutions
    # - reduce bandwidth required for viewing the live stream. Width is computed to match known aspect ratio.
    height: null
    # -- Optional: Set the encode quality of the live stream (default: shown below)
    # - 1 is the highest quality, and 31 is the lowest. Lower quality feeds utilize less CPU resources.
    quality: null

  timestamp_style:
    # -- Enable it to add the configuration in the config file
    render_config: false
    # -- Optional: Position of the timestamp
    # - "tl" (top left), "tr" (top right), "bl" (bottom left), "br" (bottom right)
    position: ""
    # -- Optional: Format specifier conform to the Python package "datetime"
    # - Additional Examples:
    # - german: "%d.%m.%Y %H:%M:%S"
    format: ""
    # -- Optional: Color of font
    color:
      # -- Enable it to add the configuration in the config file
      render_config: false
      # -- All Required when color is specified (default: shown below)
      red: 255
      green: 255
      blue: 255
    # -- Optional: Line thickness of font (default: shown below)
    thickness: null
    # -- Optional: Effect of lettering (default: shown below)
    # - None (No effect),
    # - "solid" (solid background in inverse color of font)
    # - "shadow" (shadow for font)
    effect: ""

  cameras:
    # -- Required: name of the camera
    - camera_name: back
      # -- Required: ffmpeg settings for the camera
      ffmpeg:
        # -- Required: A list of input streams for the camera. See documentation for more information.
        inputs:
          # -- Required: the path to the stream
          - path: rtsp://viewer:password@10.0.10.10:554/cam/realmonitor?channel=1&subtype=2
            # -- Required: list of roles for this stream. valid values are: detect,record,rtmp
            # - NOTICE: In addition to assigning the record, and rtmp roles,
            # - they must also be enabled in the camera config.
            roles:
              - detect
              - rtmp
            # -- Optional: stream specific global args
            global_args: ""
            # - Optional: stream specific hwaccel args
            hwaccel_args: ""
            # - Optional: stream specific input args
            input_args: ""
            # - Optional: stream specific output args
            output_args:
              detect: ""
              record: ""
              rtmp: ""
        # -- Optional: camera specific global args
        global_args: ""
        # -- Optional: camera specific hwaccel args
        hwaccel_args: ""
        # -- Optional: camera specific input args
        input_args: ""
        # -- Optional: camera specific output args
        output_args:
          detect: ""
          record: ""
          rtmp: ""
      # -- Optional: timeout for highest scoring image before allowing it
      # - to be replaced by a newer image.
      best_image_timeout: 60
      # -- Optional: zones for this camera
      zones:
        # -- Required: name of the zone
        # - NOTE: This must be different than any camera names, but can match with another zone on another camera
        - name: front_steps
          # -- Required: List of x,y coordinates to define the polygon of the zone.
          # - NOTE: Presence in a zone is evaluated only based on the bottom center of the objects bounding box.
          coordinates: 545,1077,747,939,788,805
          # -- Optional: List of objects that can trigger this zone (default: all tracked objects)
          objects: []
          # - person
          # -- Optional: Zone level object filters.
          # -NOTE: The global and camera filters are applied upstream.
          filters: []
          # - object: person
          #   min_area: null
          #   max_area: null
          #   threshold: ""
      # -- Optional: Configuration for the jpg snapshots published via MQTT
      mqtt:
        # -- Enable it to add the configuration in the config file
        render_config: false
        # -- Optional: Enable publishing snapshot via mqtt for camera
        # - NOTE: Only applies to publishing image data to MQTT via 'frigate/<camera_name>/<object_name>/snapshot'.
        # - All other messages will still be published.
        enabled: true
        # -- Optional: print a timestamp on the snapshots
        timestamp: true
        # -- Optional: draw bounding box on the snapshots
        bounding_box: true
        # -- Optional: crop the snapshot
        crop: true
        # -- Optional: height to resize the snapshot to
        height: null
        # -- Optional: jpeg encode quality
        quality: null
        # -- Optional: Restrict mqtt messages to objects that entered any of the listed zones
        required_zones: []
      # -- Optional: Configuration for how camera is handled in the GUI.
      ui:
        # -- Enable it to add the configuration in the config file
        render_config: false
        # -- Optional: Adjust sort order of cameras in the UI. Larger numbers come later
        # - By default the cameras are sorted alphabetically.
        order: null
        # -- Optional: Whether or not to show the camera in the Frigate UI
        dashboard: true

ingress:
  rtmp:
    autoLink: true

service:
  main:
    ports:
      main:
        port: 10500
        protocol: http
        targetPort: 5000
  rtmp:
    enabled: true
    ports:
      rtmp:
        enabled: true
        port: 1935
        targetPort: 1935

persistence:
  media:
    enabled: true
    mountPath: /media
  db:
    enabled: true
    mountPath: /db
  frigate-config:
    enabled: true
    mountPath: /config
    type: configmap
    objectName: frigate-config
    items:
      - key: config.yml
        path: config.yml

portal:
  open:
    enabled: true

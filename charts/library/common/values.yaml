global:
  # -- Set an override for the prefix of the fullname
  nameOverride:
  # -- Set the entire name definition
  fullnameOverride:

controller:
  # -- Set the controller type.
  # Valid options are deployment, daemonset or statefulset
  type: deployment
  # -- Set annotations on the deployment/statefulset/daemonset
  annotations: {}
  # -- Set labels on the deployment/statefulset/daemonset
  labels: {}
  # -- Number of desired pods
  replicas: 1
  # -- Set the controller upgrade strategy
  # For Deployments, valid values are Recreate (default) and RollingUpdate.
  # For StatefulSets, valid values are OnDelete and RollingUpdate (default).
  # DaemonSets ignore this.
  strategy:
  rollingUpdate:
    # -- Set deployment RollingUpdate max unavailable
    unavailable:
    # -- Set deployment RollingUpdate max surge
    surge:
    # -- Set statefulset RollingUpdate partition
    partition:
  # -- ReplicaSet revision history limit
  revisionHistoryLimit: 3

image:
  # -- image repository
  repository:
  # -- image tag
  tag:
  # -- image pull policy
  pullPolicy:

# -- Override the command(s) for the default container
command: []
# -- Override the args for the default container
args: []

# -- Set annotations on the pod
podAnnotations: {}

# -- Add a Horizontal Pod Autoscaler
# @default -- <disabled>
autoscaling:
  enabled: false
  target:  # deploymentname
  minReplicas:  # 1
  maxReplicas:  # 100
  targetCPUUtilizationPercentage:  # 80
  targetMemoryUtilizationPercentage:  # 80

serviceAccount:
  # -- Specifies whether a service account should be created
  create: false

  # -- Annotations to add to the service account
  annotations: {}

  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# -- Use this to populate a secret with the values you specify.
# Be aware that these values are not encrypted by default, and could therefore visible
# to anybody with access to the values.yaml file.
secret: {}
  # PASSWORD: my-password

# -- Main environment variables. Template enabled.
# Syntax options:
# A) TZ: UTC
# B) PASSWD: '{{ .Release.Name }}'
# C) PASSWD:
#      envFrom:
#        ...
# D) - name: TZ
#      value: UTC
# E) - name: TZ
#      value: '{{ .Release.Name }}'
env: {}
## Variables with values set from templates, example
## With a release name of: demo, the example env value will be: demo-admin
envTpl: {}
  # TEMPLATE_VALUE: "{{ .Release.Name }}-admin"

## Variables with values from (for example) the Downward API
## See https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/
envValueFrom: {}
  # NODE_NAME:
  #   fieldRef:
  #     fieldPath: spec.nodeName

envFrom: []
# - configMapRef:
#     name: config-map-name
# - secretRef:
#     name: secret-name
# -- Custom priority class for different treatment by the scheduler
priorityClassName:  # system-node-critical

# -- Allows specifying a custom scheduler name
schedulerName:  # awkward-dangerous-scheduler

# -- Allows specifying explicit hostname setting
hostname:

# -- When using hostNetwork make sure you set dnsPolicy to `ClusterFirstWithHostNet`
hostNetwork: false

# -- Defaults to "ClusterFirst" if hostNetwork is false and "ClusterFirstWithHostNet" if hostNetwork is true.
dnsPolicy:  # ClusterFirst

# -- Optional DNS settings, configuring the ndots option may resolve nslookup issues on some Kubernetes setups.
dnsConfig: {}
#   options:
#     - name: ndots
#       value: "1"

# -- Enable/disable the generation of environment variables for services.
# [[ref]](https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#accessing-the-service)
enableServiceLinks: true

# -- Configure the Security Context for the Pod
podSecurityContext: {}

# -- Configure the Security Context for the main container
securityContext: {}

# -- Configure the lifecycle for the main container
lifecycle: {}

# -- Specify any initContainers here. Yaml will be passed in to the Pod as-is.
initContainers: []

# -- Specify any additional containers here. Yaml will be passed in to the Pod as-is.
additionalContainers: []

# -- Probe configuration
# -- [[ref]](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
# @default -- See below
probes:
  # -- Liveness probe configuration
  # @default -- See below
  liveness:
    # -- Enable the liveness probe
    enabled: true
    # -- Set this to `true` if you wish to specify your own livenessProbe
    custom: false
    # -- The spec field contains the values for the default livenessProbe.
    # If you selected `custom: true`, this field holds the definition of the livenessProbe.
    # @default -- See below
    spec:
      initialDelaySeconds: 2
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 5

  # -- Redainess probe configuration
  # @default -- See below
  readiness:
    # -- Enable the readiness probe
    enabled: true
    # -- Set this to `true` if you wish to specify your own readinessProbe
    custom: false
    # -- The spec field contains the values for the default readinessProbe.
    # If you selected `custom: true`, this field holds the definition of the readinessProbe.
    # @default -- See below
    spec:
      initialDelaySeconds: 2
      periodSeconds: 10
      timeoutSeconds: 2
      failureThreshold: 5

  # -- Startup probe configuration
  # @default -- See below
  startup:
    # -- Enable the startup probe
    enabled: true
    # -- Set this to `true` if you wish to specify your own startupProbe
    custom: false
    # -- The spec field contains the values for the default startupProbe.
    # If you selected `custom: true`, this field holds the definition of the startupProbe.
    # @default -- See below
    spec:
      initialDelaySeconds: 3
      timeoutSeconds: 2
      ## This means it has a maximum of 5*30=150 seconds to start up before it fails
      periodSeconds: 5
      failureThreshold: 60

# -- Configure the services for the chart here.
# Additional services can be added by adding a dictionary key similar to the 'main' service.
# @default -- See below
service:
  main:
    # -- Enables or disables the service
    enabled: true

    # -- Make this the primary service (used in probes, notes, etc...).
    # If there is more than 1 service, make sure that only 1 service is marked as primary.
    primary: true

    # -- Override the name suffix that is used for this service
    nameOverride:

    # -- Set the service type
    type: ClusterIP

    # -- Provide additional annotations which may be required.
    annotations: {}

    # -- Provide additional labels which may be required.
    labels: {}

    # -- Configure the Service port information here.
    # Additional ports can be added by adding a dictionary key similar to the 'http' service.
    # @default -- See below
    ports:
      main:
        # -- Enables or disables the port
        enabled: true

        # -- Make this the primary port (used in probes, notes, etc...)
        # If there is more than 1 service, make sure that only 1 port is marked as primary.
        primary: true

        # -- The port number
        port:

        # -- Port protocol.
        # Support values are `HTTP`, `HTTPS`, `TCP` and `UDP`.
        # HTTPS and HTTPS spawn a TCP service and get used for internal URL and name generation
        protocol: HTTP

        # -- Specify a service targetPort if you wish to differ the service port from the application port.
        # If `targetPort` is specified, this port number is used in the container definition instead of
        # the `port` value. Therefore named ports are not supported for this field.
        targetPort:

        # -- Specify the nodePort value for the LoadBalancer and NodePort service types.
        # [[ref]](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport)
        nodePort:

# -- Configure the ingresses for the chart here.
# Additional ingresses can be added by adding a dictionary key similar to the 'main' ingress.
# @default -- See below
ingress:
  main:
    # -- Enables or disables the ingress
    enabled: false

    # -- Make this the primary ingress (used in probes, notes, etc...).
    # If there is more than 1 ingress, make sure that only 1 ingress is marked as primary.
    primary: true

    # -- Override the name suffix that is used for this ingress.
    nameOverride:

    # -- Provide additional annotations which may be required.
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"

    # -- Provide additional labels which may be required.
    labels: {}

    # -- Set the ingressClass that is used for this ingress.
    # Requires Kubernetes >=1.19
    ingressClassName:  # "nginx"

    ## Configure the hosts for the ingress
    hosts:
      -  # -- Host address. Helm template can be passed.
        host: chart-example.local
        ## Configure the paths for the host
        paths:
          -  # -- Path.  Helm template can be passed.
            path: /
            # -- Ignored if not kubeVersion >= 1.14-0
            pathType: Prefix
            service:
              # -- Overrides the service name reference for this path
              name:
              # -- Overrides the service port reference for this path
              port:

    # -- Configure TLS for the ingress. Both secretName and hosts can process a Helm template.
    tls: []
    #  - secretName: chart-example-tls
    # -- Create a secret from a GUI selected TrueNAS SCALE certificate
    #    scaleCert: true
    #    hosts:
    #      - chart-example.local

# -- Configure the persistent volumes for the chart here.
# Additional items can be added by adding a dictionary key similar to the 'config' key.
# @default -- See below
persistence:
  # -- Default persistence for configuration files.
  # @default -- See below
  config:
    # -- Enables or disables the persistent volume
    enabled: false

    # -- Where to mount the volume in the main container.
    mountPath: /config

    # -- Override the name suffix that is used for this volume.
    nameOverride:

    emptyDir:
      # -- Create an emptyDir volume instead of a persistent volume.
      # [[ref]] (https://kubernetes.io/docs/concepts/storage/volumes/#emptydir)
      enabled: false

    # -- Storage Class for the config volume.
    # If set to `-`, dynamic provisioning is disabled.
    # If set to `SCALE-ZFS`, the default provisioner for TrueNAS SCALE is used.
    # If set to something else, the given storageClass is used.
    # If undefined (the default) or set to null, no storageClassName spec is set, choosing the default provisioner.
    storageClass:  # "-"

    # -- If you want to reuse an existing claim, the name of the existing PVC can be passed here.
    existingClaim:  # your-claim

    # -- Used in conjunction with `existingClaim`. Specifies a sub-path inside the referenced volume instead of its root
    subPath:  # some-subpath

    # -- AccessMode for the persistent volume.
    # Make sure to select an access mode that is supported by your storage provider!
    # [[ref]](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes)
    accessMode: ReadWriteOnce

    # -- The amount of storage that is requested for the persistent volume.
    size: 1Gi

    # - Set to true to retain the PVC upon `helm uninstall`
    skipuninstall: false

  shared:
    # -- Create an emptyDir volume to share between all containers
    enabled: false
    emptyDir:
      enabled: true
    # -- Where to mount the shared volume in the main container.
    mountPath: /shared

# -- Mount a path on the host to the main container.
hostPathMounts: []
  # - name: "data"
  #   enabled: false
  #   emptyDir: false
  #   mountPath: "/data"
  #   subPath: some-subpath
  #   hostPath: ""
  #   readOnly: false

# -- Specify any additional volumes here. (e.g. to mount nfs volumes directly)
additionalVolumes: []

# -- Specify any additional volume mounts for the main container here.
additionalVolumeMounts: []

# -- Used in conjunction with `controller.type: statefulset` to create individual disks for each instance.
volumeClaimTemplates: []
# - name: data
#   mountPath: /data
#   accessMode: "ReadWriteOnce"
#   size: 1Gi
# - name: backup
#   mountPath: /backup
#   subPath: theSubPath
#   accessMode: "ReadWriteOnce"
#   size: 2Gi
#   storageClass: cheap-storage-class

# -- Node selection constraint
# [[ref]](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)
nodeSelector: {}

# -- Defines affinity constraint rules.
# [[ref]](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
affinity: {}

# -- Specify taint tolerations
# [[ref]](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
tolerations: []

# -- Use hostAliases to add custom entries to /etc/hosts - mapping IP addresses to hostnames.
# [[ref]](https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/)
hostAliases: []
# - ip: "192.168.1.100"
#   hostnames:
#   - "example.com"
#   - "www.example.com"

# -- Set the resource requests / limits for the main container.
resources: {}
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- The common chart supports several add-ons. These can be configured under this key.
# @default -- See below
addons:

  # -- The common chart supports adding a VPN add-on. It can be configured under this key.
  # For more info, check out [our docs](http://docs.k8s-at-home.com/our-helm-charts/common-library-add-ons/#wireguard-vpn)
  # @default -- See values.yaml
  vpn:
    # -- Enable running a VPN in the pod to route traffic through a VPN
    enabled: false

    # -- Specify the VPN type. Valid options are openvpn or wireguard
    type: openvpn

    # -- OpenVPN specific configuration
    # @default -- See below
    openvpn:
      image:
        # -- Specify the openvpn client image
        repository: dperson/openvpn-client
        # -- Specify the openvpn client image tag
        tag: latest
        # -- Specify the openvpn client image pull policy
        pullPolicy: IfNotPresent

      # -- Credentials to connect to the VPN Service (used with -a)
      auth:  # "user;password"
      # -- Optionally specify an existing secret that contains the credentials.
      # Credentials should be stored under the `VPN_AUTH` key
      authSecret:  # my-vpn-secret

    # -- WireGuard specific configuration
    # @default -- See below
    wireguard:
      image:
        # -- Specify the WireGuard image
        repository: docker pull ghcr.io/k8s-at-home/wireguard
        # -- Specify the WireGuard image tag
        tag: v1.0.20210424
        # -- Specify the WireGuard image pull policy
        pullPolicy: IfNotPresent

    # -- Set the VPN container securityContext
    # @default -- See values.yaml
    securityContext:
      capabilities:
        add:
          - NET_ADMIN
          - SYS_MODULE

    # -- All variables specified here will be added to the vpn sidecar container
    # See the documentation of the VPN image for all config values
    env: {}
      # TZ: UTC

    # -- Provide a customized vpn configuration file to be used by the VPN.
    configFile:  # |-
      # Some Example Config
      # remote greatvpnhost.com 8888
      # auth-user-pass
      # Cipher AES

    # -- Reference an existing secret that contains the VPN configuration file
    # The chart expects it to be present under the `vpnConfigfile` key.
    configFileSecret:

    # -- Provide custom up/down scripts that can be used by the vpn configuration.
    # @default -- See values.yaml
    scripts:
      up:  # |-
        # #!/bin/bash
        # echo "connected" > /shared/vpnstatus
      down:  # |-
        # #!/bin/bash
        # echo "disconnected" > /shared/vpnstatus

    additionalVolumeMounts: []

    # -- Optionally specify a livenessProbe, e.g. to check if the connection is still
    # being protected by the VPN
    livenessProbe: {}
      # exec:
      #   command:
      #     - sh
      #     - -c
      #     - if [ $(curl -s https://ipinfo.io/country) == 'US' ]; then exit 0; else exit $?; fi
      # initialDelaySeconds: 30
      # periodSeconds: 60
      # failureThreshold: 1

    # If set to true, will deploy a network policy that blocks all outbound
    # traffic except traffic specified as allowed
    networkPolicy:
      enabled: false

      # The egress configuration for your network policy, All outbound traffic
      # From the pod will be blocked unless specified here. Your cluster must
      # have a CNI that supports network policies (Canal, Calico, etc...)
      # https://kubernetes.io/docs/concepts/services-networking/network-policies/
      # https://github.com/ahmetb/kubernetes-network-policy-recipes
      egress:
        # - to:
        #   - ipBlock:
        #       cidr: 0.0.0.0/0
        #   ports:
        #   - port: 53
        #     protocol: UDP
        #   - port: 53
        #     protocol: TCP

  # -- The common library supports adding a code-server add-on to access files. It can be configured under this key.
  # For more info, check out [our docs](http://docs.k8s-at-home.com/our-helm-charts/common-library-add-ons/#code-server)
  # @default -- See values.yaml
  codeserver:
    # -- Enable running a code-server container in the pod
    enabled: false

    image:
      # -- Specify the code-server image
      repository: codercom/code-server
      # -- Specify the code-server image tag
      tag: 3.9.2
      # -- Specify the code-server image pull policy
      pullPolicy: IfNotPresent

    # -- Set any environment variables for code-server here
    env: {}
      # TZ: UTC

    # -- Set codeserver command line arguments.
    # Consider setting --user-data-dir to a persistent location to preserve code-server setting changes
    args:
      - --auth
      - none
      # - --user-data-dir
      # - "/config/.vscode"

    # -- Specify a list of volumes that get mounted in the code-server container.
    # At least 1 volumeMount is required!
    volumeMounts: []
    # - name: config
    #   mountPath: /data/config

    # -- Specify the working dir that will be opened when code-server starts
    # If not given, the app will default to the mountpah of the first specified volumeMount
    workingDir: ""

    # -- Optionally allow access a Git repository by passing in a private SSH key
    # @default -- See below
    git:
      # -- Raw SSH private key
      deployKey: ""
      # -- Base64-encoded SSH private key. When both variables are set, the raw SSH key takes precedence.
      deployKeyBase64: ""
      # -- Existing secret containing SSH private key
      # The chart expects it to be present under the `id_rsa` key.
      deployKeySecret: ""

    service:
      # -- Enable a service for the code-server add-on.
      enabled: true
      type: ClusterIP
      # Specify the default port information
      ports:
        codeserver:
          port: 12321
          enabled: true
          protocol: TCP
          targetPort: codeserver
          ## Specify the nodePort value for the LoadBalancer and NodePort service types.
          ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
          ##
          # nodePort:
      annotations: {}
      labels: {}

    ingress:
      # -- Enable an ingress for the code-server add-on.
      enabled: false
      nameOverride: codeserver
      annotations: {}
        # kubernetes.io/ingress.class: nginx
        # kubernetes.io/tls-acme: "true"
      labels: {}
      hosts:
        - host: code.chart-example.local
          paths:
            - path: /
              # Ignored if not kubeVersion >= 1.14-0
              pathType: Prefix
      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - code.chart-example.local

    securityContext:
      runAsUser: 0

  # -- The common library supports adding a promtail add-on to to access logs and ship them to loki. It can be configured under this key.
  # @default -- See values.yaml
  promtail:
    # -- Enable running a promtail container in the pod
    enabled: false

    image:
      # -- Specify the promtail image
      repository: grafana/promtail
      # -- Specify the promtail image tag
      tag: 2.2.0
      # -- Specify the promtail image pull policy
      pullPolicy: IfNotPresent

    # -- Set any environment variables for promtail here
    env: {}

    # -- Set promtail command line arguments
    args: []

    # -- The URL to Loki
    loki: ""

    # -- The paths to logs on the volume
    logs: []
    # - name: log
    #   path: /config/logs/*.log

    # -- Specify a list of volumes that get mounted in the promtail container.
    # At least 1 volumeMount is required!
    volumeMounts: []
    # - name: config
    #   mountPath: /config
    #   readOnly: true

    securityContext:
      runAsUser: 0
